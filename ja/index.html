<!DOCTYPE html><html lang="ja" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  
  
  <meta name="generator" content="Wowchemy 5.0.0-beta.1 for Hugo">
  

  

  
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="米谷　竜">

  
  
  
    
  
  <meta name="description" content="">

  
  <link rel="alternate" hreflang="en" href="https://yonetaniryo.github.io/">
  
  <link rel="alternate" hreflang="ja" href="https://yonetaniryo.github.io/ja/">

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  

  
  
  
  
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css" integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.2.2/lazysizes.min.js" integrity="sha512-TmDwFLhg3UA4ZG0Eb4MIyT1O1Mb+Oww5kFG0uHqXsdbyZz9DcvYQhKpGgNkamAI6h2lGGZq2X8ftOJvF/XjTUg==" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      
        
      

      
    
      

      
      

      
    
      

      
      

      
    

  

  
  
  
    
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
    
  

  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.min.b01f95fd5bb44f4d16e49a2070912cfa.css">

  




  

  


  
  
  <script src="https://identity.netlify.com/v1/netlify-identity-widget.js"></script>
  

  
  <link rel="alternate" href="/ja/index.xml" type="application/rss+xml" title="Webpage of Ryo Yonetani">
  

  <link rel="manifest" href="/ja/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="https://yonetaniryo.github.io/ja/">

  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Webpage of Ryo Yonetani">
  <meta property="og:url" content="https://yonetaniryo.github.io/ja/">
  <meta property="og:title" content="Webpage of Ryo Yonetani">
  <meta property="og:description" content=""><meta property="og:image" content="https://yonetaniryo.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png">
  <meta property="twitter:image" content="https://yonetaniryo.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png"><meta property="og:locale" content="ja">
  
    
  

  

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "WebSite",
  "potentialAction": {
    "@type": "SearchAction",
    "target": "https://yonetaniryo.github.io/?q={search_term_string}",
    "query-input": "required name=search_term_string"
  },
  "url": "https://yonetaniryo.github.io/"
}
</script>


  


  


  





  <title>Webpage of Ryo Yonetani</title>

</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#navbar-main" class="page-wrapper  ">

  
  
  
  
  
  <script src="/js/wowchemy-init.js"></script>

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="検索..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  <div class="page-header">
    












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/ja/">Webpage of Ryo Yonetani</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="ナビゲーションの切り替え">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/ja/">Webpage of Ryo Yonetani</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/ja/#about" data-target="#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/ja/#awards" data-target="#awards"><span>学術活動</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/ja/#publications" data-target="#publications"><span>発表論文</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
          <i class="fas fa-moon" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      
      <li class="nav-item dropdown i18n-dropdown">
        <a href="#" class="nav-link " data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-globe mr-1" aria-hidden="true"></i></a>
        <div class="dropdown-menu">
          <div class="dropdown-item dropdown-item-active">
            <span>日本語</span>
          </div>
          
          <a class="dropdown-item" href="https://yonetaniryo.github.io/" data-target="/">
            <span>English</span>
          </a>
          
        </div>
      </li>
      

    </ul>

  </div>
</nav>


  </div>

  <div class="page-body">
    











  
<span class="js-widget-page d-none"></span>





  
  
  
  




  
  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  
  

  
  <section id="about" class="home-section wg-about  "  >
   <div class="home-section-bg " ></div>
    <div class="container">

    

      




  










<div class="row">
  <div class="col-12 col-lg-4">
    <div id="profile">

      
      
      <img class="avatar avatar-circle" src="/ja/authors/admin/avatar_hucece6bc10d491cb75c2ab72643fefe8a_242346_270x270_fill_q75_lanczos_center.jpg" alt="米谷　竜">
      

      <div class="portrait-title">
        <h2>米谷　竜</h2>
        

        
      </div>

      <ul class="network-icon" aria-hidden="true">
        
        
        
        
          
        
        
        
        
        
        <li>
          <a href="mailto:ryo.yonetani@sinicx.com"  aria-label="envelope">
            <i class="fas fa-envelope big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://twitter.com/RYonetani" target="_blank" rel="noopener" aria-label="twitter">
            <i class="fab fa-twitter big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://scholar.google.com/citations?user=DYXnRWEAAAAJ" target="_blank" rel="noopener" aria-label="graduation-cap">
            <i class="fas fa-graduation-cap big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://github.com/yonetaniryo" target="_blank" rel="noopener" aria-label="github">
            <i class="fab fa-github big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://www.linkedin.com/in/ryo-yonetani-75633b163/" target="_blank" rel="noopener" aria-label="linkedin">
            <i class="fab fa-linkedin big-icon"></i>
          </a>
        </li>
        
      </ul>

    </div>
  </div>
  <div class="col-12 col-lg-8">

    
    

    <ul>
<li><strong>プリンシパルインベスティゲーター</strong> @ <a href="https://www.omron.com/sinicx/" target="_blank" rel="noopener">オムロンサイニックエックス</a></li>
<li><strong>協力研究員</strong> @ <a href="https://www.ut-vision.org/sato-lab/" target="_blank" rel="noopener">東京大学 生産技術研究所 佐藤洋一研究室</a></li>
</ul>


    <div class="row">

      
      <div class="col-md-5">
        <h3>興味・関心</h3>
        <ul class="ul-interests">
          
          <li>コンピュータビジョン（視覚的予測、一人称ビジョン）</li>
          
          <li>機械学習（フェデレーテッドラーング、ロボット学習）</li>
          
        </ul>
      </div>
      

      
      <div class="col-md-7">
        <h3>学歴</h3>
        <ul class="ul-edu fa-ul">
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">博士（情報学）, 2013</p>
              <p class="institution">京都大学</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">修士（情報学）, 2010</p>
              <p class="institution">京都大学</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">学士（電気電子工学）, 2008</p>
              <p class="institution">京都大学</p>
            </div>
          </li>
          
        </ul>
      </div>
      

    </div>
  </div>
</div>


    

    </div>
  </section>

  
  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  
  

  
  <section id="experience" class="home-section wg-experience  "  >
   <div class="home-section-bg " ></div>
    <div class="container">

    
      <div class="row  ">
      
        
          <div class="col-12 col-lg-4 section-heading">
            <h1>職歴</h1>
            
          </div>
        
      
    

      




<div class="col-12 col-lg-8">
  

  
  
  
  <div class="row experience">
    
    <div class="col-auto text-center flex-column d-none d-sm-flex">
      <div class="row h-50">
        <div class="col ">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
      <div class="m-2">
        <span class="badge badge-pill border exp-fill">&nbsp;</span>
      </div>
      <div class="row h-50">
        <div class="col border-right">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
    </div>
    
    <div class="col py-2">
      <div class="card">
        <div class="card-body">
          <h4 class="card-title exp-title text-muted mt-0 mb-1">プリンシパルインベスティゲーター</h4>
          <h4 class="card-title exp-company text-muted my-0">オムロンサイニックエックス株式会社</h4>
          <div class="text-muted exp-meta">
            Apr 2020 –
            
              Present
            
            
              <span class="middot-divider"></span>
              <span>Tokyo, Japan</span>
            
          </div>
          
        </div>
      </div>
    </div>
  </div>
  
  <div class="row experience">
    
    <div class="col-auto text-center flex-column d-none d-sm-flex">
      <div class="row h-50">
        <div class="col border-right">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
      <div class="m-2">
        <span class="badge badge-pill border ">&nbsp;</span>
      </div>
      <div class="row h-50">
        <div class="col border-right">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
    </div>
    
    <div class="col py-2">
      <div class="card">
        <div class="card-body">
          <h4 class="card-title exp-title text-muted mt-0 mb-1">シニアリサーチャー</h4>
          <h4 class="card-title exp-company text-muted my-0">オムロンサイニックエックス株式会社</h4>
          <div class="text-muted exp-meta">
            Jan 2018 –
            
              Dec 2019
            
            
              <span class="middot-divider"></span>
              <span>Tokyo, Japan</span>
            
          </div>
          
        </div>
      </div>
    </div>
  </div>
  
  <div class="row experience">
    
    <div class="col-auto text-center flex-column d-none d-sm-flex">
      <div class="row h-50">
        <div class="col border-right">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
      <div class="m-2">
        <span class="badge badge-pill border ">&nbsp;</span>
      </div>
      <div class="row h-50">
        <div class="col border-right">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
    </div>
    
    <div class="col py-2">
      <div class="card">
        <div class="card-body">
          <h4 class="card-title exp-title text-muted mt-0 mb-1">訪問研究員</h4>
          <h4 class="card-title exp-company text-muted my-0">カーネギーメロン大学</h4>
          <div class="text-muted exp-meta">
            Sep 2016 –
            
              Aug 2017
            
            
              <span class="middot-divider"></span>
              <span>Pittsburgh, CA, USA</span>
            
          </div>
          
        </div>
      </div>
    </div>
  </div>
  
  <div class="row experience">
    
    <div class="col-auto text-center flex-column d-none d-sm-flex">
      <div class="row h-50">
        <div class="col border-right">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
      <div class="m-2">
        <span class="badge badge-pill border ">&nbsp;</span>
      </div>
      <div class="row h-50">
        <div class="col ">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
    </div>
    
    <div class="col py-2">
      <div class="card">
        <div class="card-body">
          <h4 class="card-title exp-title text-muted mt-0 mb-1">助教</h4>
          <h4 class="card-title exp-company text-muted my-0">東京大学 生産技術研究所（佐藤洋一研究室）</h4>
          <div class="text-muted exp-meta">
            Apr 2014 –
            
              Dec 2018
            
            
              <span class="middot-divider"></span>
              <span>Tokyo, Japan</span>
            
          </div>
          
        </div>
      </div>
    </div>
  </div>
  
  
</div>


    
      </div>
    

    </div>
  </section>

  
  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  
  

  
  <section id="awards" class="home-section wg-pages  "  >
   <div class="home-section-bg " ></div>
    <div class="container">

    
      <div class="row  ">
      
        
          <div class="col-12 col-lg-4 section-heading">
            <h1>学術活動</h1>
            
          </div>
        
      
    

      








  
























  





  




<div class="col-12 col-lg-8">

  <h1 id="受賞">受賞</h1>
<h2 id="本人によるもの">本人によるもの</h2>
<ul>
<li>MIRUインタラクティブ賞, 画像の認識・理解シンポジウム, 2019</li>
<li>Outstanding Reviewer, IEEE Conference on Computer Vision and Pattern Recognition, 2017</li>
<li>山下記念研究賞, 情報処理学会, 2016</li>
<li>情報・システムソサイエティ論文賞, 電子情報通信学会, 2014</li>
<li>H25 PRMU研究奨励賞, 電子情報通信学会パターン認識とメディア理解研究会, 2014</li>
<li>MIRU優秀学生論文賞, 画像の認識・理解シンポジウム, 2012</li>
<li>IBM Best Student Paper Award (Track IV: Biometrics and Human Computer Interaction), International Conference on Pattern Recognition, 2010</li>
</ul>
<h2 id="共著学生によるもの">共著学生によるもの</h2>
<ul>
<li>杉田祐樹, インタラクティブ発表賞, インタラクション2017, 2017</li>
<li>村上晋太郎, CVIM奨励賞, 情報処理学会コンピュータビジョンとイメージメディア研究会, 2016</li>
<li>樋口未来, CVIM奨励賞, 情報処理学会コンピュータビジョンとイメージメディア研究会, 2016</li>
</ul>
<h1 id="研究助成">研究助成</h1>
<h2 id="代表者">代表者</h2>
<ul>
<li>JST戦略的創造研究推進事業（ACT-I）, “プライバシー保護一人称ビジョン”, 2016 - 2018</li>
<li>生産技術研究奨励会特定研究奨励助成, “一人称視点映像の共通注目シーン解析”, 2016 - 2017</li>
<li>科学研究費補助金若手研究B, “映像コンテンツの顕著性変動解析による特徴ベース視線推定”, 2015 - 2017</li>
<li>栢森情報科学振興財団助成, “複数装着型カメラ映像からのインタラクション認識技術の開発”, 2015 - 2017</li>
<li>大川情報通信基金研究助成, “ディスプレイを高原として用いた視線計測技術に関する研究”, 2015 - 2016</li>
<li>日本学術振興会特別研究員研究助成, “時区間ハイブリッドダイナミカルシステムを用いた心の分析とモデル化”, 2012-2014</li>
</ul>
<h2 id="共同研究者-研究協力者">共同研究者, 研究協力者</h2>
<ul>
<li>JST戦略的創造研究推進事業（CREST）, “集合視による注視・行動解析に基づくライフイノベーション創出”（代表: 佐藤洋一）, 2014 - 2018</li>
<li>JST戦略的国際共同研究プログラム（SICORP）, “多様なカメラを活用した群衆行動の変化検出”（代表: 佐藤洋一）, 2017 - 2018</li>
</ul>
<h1 id="学会活動">学会活動</h1>
<h2 id="チェア">チェア</h2>
<ul>
<li>画像の認識・理解シンポジウム (MIRU) 財務委員長, 2019, 2021</li>
<li>情報処理学会コンピュータビジョンとイメージメディア（CVIM）研究会 幹事, 2018 - 現在</li>
<li>情報処理学会 論文誌ジャーナル/JIP編集委員会 編集委員, 2017 - 2018</li>
<li><strong>Publication Chair</strong> @ <a href="http://www.mva-org.jp/mva2021/" target="_blank" rel="noopener">International Conference on Machine Vision Applications (MVA), 2021</a></li>
<li><strong>Publicity Chair</strong> @ <a href="https://accv2020.github.io/" target="_blank" rel="noopener">Asian Conference on Computer Vision (ACCV), 2020</a></li>
<li><strong>Program Chair</strong> @ <a href="https://printeps.org/HDC2017/" target="_blank" rel="noopener">International Workshop on Human Activity Analysis with Highly Diverse Cameras (HDC), 2017</a></li>
<li><strong>Sponsorship Chair</strong> @ <a href="http://icmi.acm.org/2016/" target="_blank" rel="noopener">International Conference on Multimodal Interaction (ICMI), 2016</a></li>
</ul>
<h2 id="査読">査読</h2>
<ul>
<li><strong>Computer vision</strong>: CVPR (2015 - Present), ICCV (2015 - Present), ECCV (2014 - Present), ACCV (2014 - Present), IEEE TPAMI, IJCV</li>
<li><strong>Robotics</strong>: ICRA (2019 - Present), IROS (2019 - Present)</li>
<li><strong>Machine learning and AI</strong>: IJCAI (2021 as a Senior Program Chair)</li>
<li><strong>Others</strong>: CHI (2017), ICPR (2014)</li>
</ul>
<h2 id="招待講演講義">招待講演、講義</h2>
<ul>
<li>サーベイ論文の書き方 ～視覚的注意モデルのサーベイを題材に～, パターン認識とメディア理解研究会, 2018</li>
<li>一人称ビジョンと集合視, 【第22回AIセミナー】 「コンピュータービジョンとAI　～人とロボットの視覚～」, 産総研 人工知能研究センター, 2018</li>
<li>グランドチャレンジは誰がやるのか, 特別セッション「今後の研究会のあり方を考える」, パターン認識とメディア理解研究会, 2018</li>
<li>一人称ビジョン, 人工知能とメディア, はこだて未来大学, 2017</li>
<li>一人称視点映像解析の最先端, 画像の認識・理解シンポジウム, 2016</li>
<li>Recognizing Micro-Actions and Reactions from Paired Egocentric Videos, 画像の認識・理解シンポジウム, 2016</li>
<li>Ego-Surfing First-Person Videos, 画像の認識・理解シンポジウム, 2015</li>
</ul>


  

  
  
  

</div>


    
      </div>
    

    </div>
  </section>

  
  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  
  

  
  <section id="publications" class="home-section wg-pages  "  >
   <div class="home-section-bg " ></div>
    <div class="container">

    
      <div class="row  ">
      
        
          <div class="col-12 col-lg-4 section-heading">
            <h1>発表論文</h1>
            
          </div>
        
      
    

      








  
























  





  




<div class="col-12 col-lg-8">

  <p><a href="http://dblp.uni-trier.de/pers/hd/y/Yonetani:Ryo" target="_blank" rel="noopener">DBLP</a> | <a href="https://scholar.google.com/citations?user=DYXnRWEAAAAJ" target="_blank" rel="noopener">Google Scholar</a> | <a href="http://ci.nii.ac.jp/nrid/9000017546008" target="_blank" rel="noopener">CiNii</a></p>
<h4 id="査読付き雑誌論文">査読付き雑誌論文</h4>
<ul>
<li>Hiroaki Minoura, Ryo Yonetani, Mai Nishimura, Yoshitaka Ushiku: &ldquo;Crowd Density Forecasting by Modeling Patch-based Dynamics&rdquo;, IEEE Robotics and Automation Letters <strong>(RA-L)</strong>, 2020.</li>
<li>Ryo Yonetani, Kris Kitani, Yoichi Sato: &ldquo;Ego-Surfing: Person Localization in First-Person Videos Using Ego-Motion Signatures&rdquo;, IEEE Transactions on Pattern Analysis and Machine Intelligence <strong>(TPAMI)</strong>, Vol.40, Issue 11, pp.2749-2761, 2018.</li>
<li>下西慶, 石川惠理奈, 米谷竜, 川嶋宏彰, 松山隆司: &ldquo;視線運動解析による興味アスペクトの推定&rdquo;, ヒューマンインタフェース学会論文誌, Vol.16, No2, pp.103-114, 2014</li>
<li>Akisato Kimura, Ryo Yonetani, Takatsugu Hirayama: &ldquo;Computational Models of Human Visual Attention and Their Implementations: A Survey&rdquo;, IEICE Transactions on Information and Systems, E96-D(3), pp.562-578, 2013</li>
<li>Ryo Yonetani, Hiroaki Kawashima, Takashi Matsuyama: Learning Spatiotemporal Gaps between Where We Look and What We Focus on&quot;, IPSJ Transactions on Computer Vision and Applications, 5, pp. 75-79, 2013</li>
<li>米谷竜, 川嶋宏彰, 加藤丈和, 松山隆司: &ldquo;映像の顕著性変動モデルを用いた視聴者の集中状態推定, 電子情報通信学会論文誌, J96-D(8), pp.1675-1687, 2013（第15回 画像の認識・理解シンポジウム推薦論文）</li>
<li>Ryo Yonetani, Hiroaki Kawashima, Takatsugu Hirayama, Takashi Matsuyama: &ldquo;Mental Focus Analysis Using the Spatio-temporal Correlation between Visual Saliency and Eye Movements&rdquo;, 情報処理学会論文誌, Vol. 52, No. 12, 2011</li>
<li>石川惠理奈, 米谷竜, 平山高嗣, 松山隆司: &ldquo;Gaze Mirroringによる注視模倣効果の分析&rdquo;, 情報処理学会論文誌, Vol.52, No.12, pp3637-3646, 2011</li>
<li>米谷竜, 川嶋宏彰, 平山高嗣, 松山隆司: &ldquo;Gaze Probing: イベント提示に基づく注視オブジェクト推定&rdquo;, ヒューマンインタフェース学会論文誌, Vol.12, No.3, pp. 125-135, 2010</li>
</ul>
<h4 id="国際会議論文">国際会議論文</h4>
<ul>
<li>Jiaxin Ma, Ryo Yonetani, Zahid Iqbal, &ldquo;Adaptive Distillation for Decentralized Learning from Heterogeneous Clients&rdquo;, International Conference on Pattern Recognition <strong>(ICPR)</strong>, 2020 <a href="https://arxiv.org/abs/2008.07948" target="_blank" rel="noopener">[arXiv]</a></li>
<li>Mai Nishimura, Ryo Yonetani, &ldquo;L2B: Learning to Balance the Safety-Efficiency Trade-off in Interactive Crowd-aware Robot Navigation&rdquo;, accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems <strong>(IROS)</strong>, 2020, <a href="https://arxiv.org/abs/2003.09207" target="_blank" rel="noopener">[arXiv]</a></li>
<li>Mohammadamin Barekatain, Ryo Yonetani, Masashi Hamaya, &ldquo;MULTIPOLAR: Multi-Source Policy Aggregation for Transfer Reinforcement Learning between Diverse Environmental Dynamics&rdquo;, International Joint Conference on Artificial Intelligence <strong>(IJCAI)</strong>, 2020 [<a href="https://arxiv.org/abs/1909.13111" target="_blank" rel="noopener">arXiv</a>]</li>
<li>Rie Kamikubo, Naoya Kato, Keita Higuchi, Ryo Yonetani, Yoichi Sato, &ldquo;Studying Effective Agents in Remote Sighted Guidance for People Navigating with Visual Impairments&rdquo;, ACM Conference on Human Factors in Computing Systems <strong>(CHI)</strong>, 2020</li>
<li>Navyata Sanghvi, Ryo Yonetani, Kris Kitani, &ldquo;Modeling Social Group Communication with Multi-Agent Imitation Learning&rdquo;, International Conference on Autonomous Agents and Multi-Agent Systems <strong>(AAMAS)</strong>, 2020 <a href="https://arxiv.org/abs/1903.01537" target="_blank" rel="noopener">[arXiv]</a></li>
<li>Naoya Yoshida, Takayuki Nishio, Masahiro Morikura, Koji Yamamoto, Ryo Yonetani, &ldquo;Hybrid-FL for Wireless Networks: Cooperative Learning Mechanism Using Non-IID Data&rdquo;, IEEE International Conference on Communications <strong>(ICC)</strong>, 2020 <a href="https://arxiv.org/abs/1905.07210" target="_blank" rel="noopener">[arXiv]</a></li>
<li>Takayuki Nishio and Ryo Yonetani: &ldquo;Client Selection for Federated Learning with Heterogeneous Resources in Mobile Edge&rdquo;, IEEE International Conference on Communications <strong>(ICC)</strong>, 2019 <a href="/2018/04/24/ny-arxiv2018.html">[project]</a></li>
<li>Nathawan Charoenkulvanich, Rie Kamikubo, Ryo Yonetani, and Yoichi Sato, &ldquo;Assisting Group Activity Analysis through Hand Detection and Identification in Multiple Egocentric Videos&rdquo;, ACM Conference on Intelligent User Interface <strong>(IUI)</strong>, 2019.</li>
<li>Yuki Sugita, Keita Higuchi, Ryo Yonetani, Rie Kamikubo, Yoichi Sato: &ldquo;Browsing Group First-Person Videos with 3D Visualization&rdquo;, accepted to ACM International Conference on Interactive Surfaces and Spaces (ISS), 2018</li>
<li>Takuma Yagi, Karttikeya Mangalam, Ryo Yonetani, Yoichi Sato: &ldquo;Future Person Localization in First-Person Videos&rdquo;, IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR, spotlight presentation)</strong>, 2018 <a href="/2018/02/19/ymys-cvpr2018.html">[project]</a></li>
<li>Rie Kamikubo, Keita Higuchi, Ryo Yonetani, Hideki Koike, Yoichi Sato, &ldquo;Exploring the Role of Tunnel Vision Simulation in the Design Cycle of Accessible Interfaces&rdquo;, International Cross-Disciplinary Conference on Web Accessibility <strong>(Web4All)</strong>, 2018</li>
<li>Ryo Yonetani, Vishnu Naresh Boddeti, Kris M. Kitani, Yoichi Sato: &ldquo;Privacy-Preserving Visual Learning Using Doubly Permuted Homomorphic Encryption&rdquo;, International Conference on Computer Vision <strong>(ICCV)</strong>, 2017 <a href="/2017/07/16/ybks-iccv2017.html">[project]</a></li>
<li>Keita Higuchi, Ryo Yonetani, Yoichi Sato: &ldquo;EgoScanning: Quickly Scanning First-Person Videos with Egocentric Elastic Timelines&rdquo;, ACM Conference on Human Factors in Computing Systems <strong>(CHI)</strong>, 2017 <a href="/2017/01/16/hys-chi2017.html">[project]</a></li>
<li>Ryo Yonetani, Kris Kitani, Yoichi Sato: &ldquo;Visual Motif Discovery via First-Person Vision&rdquo;, European Conference on Computer Vision <strong>(ECCV)</strong>, 2016 <a href="/2016/07/12/yks-eccv2016.html">[project]</a></li>
<li>Ryo Yonetani, Kris Kitani, Yoichi Sato: &ldquo;Recognizing Micro-Actions and Reactions from Paired Egocentric Videos&rdquo;, IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2016 <a href="/2016/03/02/yks-cvpr2016.html">[project]</a></li>
<li>Keita Higuchi, Ryo Yonetani, Yoichi Sato: &ldquo;Can Eye Help You?: Effects of Visualizing Eye Fixations on Remote Collaboration Scenarios for Physical Tasks&rdquo;, ACM Conference on Human Factors in Computing Systems <strong>(CHI)</strong>, 2016 <a href="/2016/01/18/hys-chi2016.html">[project]</a></li>
<li>Ryo Yonetani, Kris Kitani, Yoichi Sato: &ldquo;Ego-Surfing First-Person Videos&rdquo;, IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2015 <a href="/2016/06/15/yks-cvpr2015.html">[project]</a></li>
<li>Ryo Yonetani, Hiroaki Kawashima, Takashi Matsuyama: &ldquo;Predicting Where We Look from Spatiotemporal Gaps&rdquo;, International Conference on Multimodal Interaction <strong>(ICMI)</strong>, 2013 <a href="/2013/12/09/ykm-icmi2013.html">[project]</a></li>
<li>Ryo Yonetani, Akisato Kimura, Hitoshi Sakano, Ken Fukuchi: &ldquo;Single Image Segmentation with Estimated Depth&rdquo;, British Machine Vision Conference <strong>(BMVC)</strong>, 2012</li>
<li>Ryo Yonetani, Hiroaki Kawashima, Takashi Matsuyama: &ldquo;Multi-mode Saliency Dynamics Model for Analyzing Gaze and Attention&rdquo;, Eye Tracking Research &amp; Applications <strong>(ETRA)</strong>, 2012 <a href="/2012/03/28/ykm-etra2012.html">[project]</a></li>
<li>Ryo Yonetani, Hiroaki Kawashima, Takatsugu Hirayama, Takashi Matsuyama: &ldquo;Gaze Probing: Event-Based Estimation of Objects Being Focused On&rdquo;, International Conference on Pattern Recognition <strong>(ICPR, IBM Best Student Paper Award)</strong>, 2010</li>
</ul>
<h4 id="国際ワークショップ論文extended-abstracts-プレプリントなど">国際ワークショップ論文，Extended Abstracts, プレプリントなど</h4>
<ul>
<li>Ryo Yonetani, Tatsunori Taniai, Mohammadamin Barekatain, Mai Nishimura, Asako Kanezaki, &ldquo;Path Planning using Neural A* Search&rdquo;, arXiv preprint, 2020 <a href="https://arxiv.org/abs/2009.07476" target="_blank" rel="noopener">[arXiv]</a></li>
<li>Ryo Yonetani, Tomohiro Takahashi, Atsushi Hashimoto, Yoshitaka Ushiku, &ldquo;Decentralized Learning of Generative Adversarial Networks from Multi-Client Non-iid Data&rdquo;, arXiv preprint, 2019 <a href="https://arxiv.org/abs/1905.09684" target="_blank" rel="noopener">[arXiv]</a></li>
<li>Navyata Sanghvi, Ryo Yonetani, Kris Kitani, &ldquo;Learning Group Communication from Demonstration&rdquo;, RSS Workshop on Models and Representations for Natural Human-Robot Communication, 2018</li>
<li>Seita Kayukawa, Keita Higuchi, Ryo Yonetani, Maanori Nakamura, Yoichi Sato, Shigeo Morishima: &ldquo;Dynamic Object Scanning: Object-Based Elastic Timeline for Quickly Browsing First-Person Videos&rdquo;, ACM Conference on Human Factors in Computing Systems Late Breaking Work <strong>(CHI-LBW)</strong>, 2018</li>
<li>Keita Higuchi, Ryo Yonetani, Yoichi Sato: &ldquo;EgoScanning: Quickly Scanning First-Person Videos with Egocentric Elastic Timelines&rdquo;, ACM SIGGRAPH Asia Emerging Technologies <strong>(SIGGRAPH-ASIA-ETECH)</strong>, 2017</li>
<li>Yifei Huang, Minjie Cai, Hiroshi Kera, Ryo Yonetani, Keita Higuchi, Yoichi Sato: &ldquo;Temporal Localization and Spatial Segmentation of Joint Attention in Multiple First-Person Video&rdquo;, International Workshop on Egocentric Perception, Interaction, and Computing <strong>(EPIC)</strong>, 2017</li>
<li>Rie Kamikubo, Keita Higuchi, Ryo Yonetani, Hideki Koike, Yoichi Sato: &ldquo;Rapid Prototyping of Accessible Interfaces with Gaze- Contiguent Tunnel Vision Simulation&rdquo;, ACM SIGACCESS International Conference on Computers and Accessibility <strong>(ASSETS)</strong>, 2017</li>
<li>Ryo Yonetani, Vishnu Naresh Boddeti, Kris Kitani, Yoichi Sato: &ldquo;Privacy-Preserving Visual Learning Using Doubly Permuted Homomorphic Encryption&rdquo;, International Workshop on The Bright and Dark Sides of Computer Vision: Challenges and Opportunities for Privacy and Security <strong>(CV-COPS)</strong>, 2017</li>
<li>Hiroshi Kera, Ryo Yonetani, Keita Higuchi, Yoichi Sato: &ldquo;Discovering Objects of Joint Attention via First-Person Sensing&rdquo;, IEEE CVPR Workshop on Egocentric (First-Person) Vision <strong>(EGOV)</strong>, 2016</li>
<li>Kei Shimonishi, Hiroaki Kawashima, Ryo Yonetani, Erina Ishikawa, Takashi Matsuyama: &ldquo;Learning Aspects of Interest from Gaze&rdquo;, ICMI Workshop on Eye Gaze in Intelligent Human Machine Interaction: Gaze in Multimodal Interaction <strong>(GazeIn)</strong>, 2013</li>
<li>Ryo Yonetani: &ldquo;Modeling Video Viewing Behaviors for Viewer State Estimation&rdquo;, ACM Multimedia Doctoral Symposium <strong>(ACMMM-DS)</strong>, 2012</li>
<li>Erina Ishikawa, Ryo Yonetani, Hiroaki Kawashima, Takatsugu Hirayama, Takashi Matsuyama: &ldquo;Semantic Interpretation of Eye Movements Using Designed Structures of Displayed Contents&rdquo;, ICMI Workshop on Eye Gaze in Intelligent Human Machine Interaction: Eye Gaze, Multimodality <strong>(GazeIn)</strong>, 2012</li>
</ul>
<h4 id="国内会議論文">国内会議論文</h4>
<ul>
<li>八木 拓真, マンガラムカーティケヤ, 米谷 竜, 佐藤 洋一, &ldquo;一人称視点映像における人物位置予測&rdquo;, 情報処理学会研究会資料 CVIM, 2018</li>
<li>粥川青汰, 樋口啓太, 中村優文, 米谷竜, 佐藤洋一, 森島繁生, ”一人称視点動画の高速閲覧に有効なキューの自動生成手法”, インタラクティブシステムとソフトウェアに関するワークショップ,  2017</li>
<li>粥川青汰, 樋口啓太, 中村優文, 米谷竜, 佐藤洋一, 森島繁生, ”物体検出とユーザ入力に基づく一人称視点映像の高速閲覧手法”, 情報処理学会コンピュータビジョンとイメージメディア研究会,  2017.</li>
<li>Yifei Huang, Minjie Cai, Hiroshi Kera, Ryo Yonetani, Keita Higuchi, Yoichi Sato: &ldquo;Spatial-temporal Segmentation of Joint Attention in Multiple First-Person Videos&rdquo;, 第20回 画像の認識理解シンポジウム, 2017</li>
<li>杉田祐樹, 樋口啓太, 米谷竜, 佐藤洋一: &ldquo;複数一人称視点映像閲覧における行動空間とカメラ位置姿勢の3次元可視化による効果&rdquo;, 情報処理学会シンポジウム　インタラクション2017, 2017**（インタラクティブ発表賞）**</li>
<li>中野雄介, 米谷竜, 樋口啓太, 佐藤洋一: &ldquo;視線を考慮した一人称視点映像からの頷き検出&rdquo;, 電子情報通信学会総合大会, 2017</li>
<li>杉田祐樹, 樋口啓太, 米谷竜, 佐藤洋一: &ldquo;複数一人称視点映像閲覧における行動空間とカメラ位置姿勢の3次元可視化による効果&rdquo;, 情報処理学会ヒューマンコンピュータインタラクション研究会, 2017</li>
<li>樋口啓太, 米谷竜, 佐藤洋一: &ldquo;伸縮タイムライン生成による一人称視点映像の高速閲覧支援&rdquo;, 第24回インタラクティブシステムとソフトウェアに関するワークショップ, 2016</li>
<li>樋口未来, 米谷竜, 木谷クリス, 佐藤洋一: &ldquo;一人称視点映像を用いたランキング学習による相対的地位の推定&rdquo;, 情報処理学会コンピュータビジョンとイメージメディア研究会, 2016**（情報処理学会CVIM研究会奨励賞）**</li>
<li>Hiroshi Kera, Ryo Yonetani, Keita Higuchi, Yoichi Sato: &ldquo;Discovering Objects of Joint Attention via First-Person Sensing&rdquo;, 第19回 画像の認識理解シンポジウム,2016</li>
<li>樋口啓太, 米谷竜, 佐藤洋一: &ldquo;手の動作に基づく複数一人称視点作業映像のアラインメント&rdquo;, 情報処理学会コンピュータビジョンとイメージメディア研究会, 2016</li>
<li>松本大輝, 米谷竜, 佐藤洋一: &ldquo;滑動性眼球運動を用いた視線計測の自動校正&rdquo;, 情報処理学会コンピュータビジョンとイメージメディア研究会, 2016</li>
<li>村上晋太郎, 米谷竜, 佐藤洋一: &ldquo;視線を利用した二人称視点動作認識&rdquo;, 情報処理学会コンピュータビジョンとイメージメディア研究会, 2016**（情報処理学会CVIM研究会奨励賞）**</li>
<li>Ryo Yonetani, Kris Kitani, Yoichi Sato: &ldquo;Ego-Surfing First-Person Videos&rdquo;, 第18回 画像の認識理解シンポジウム, 2015</li>
<li>松本 大輝, 米谷 竜, 佐藤 洋一, &ldquo;滑動性眼球運動を用いた視線計測の自動校正&rdquo;, 第18回 画像の認識理解シンポジウム, 2015</li>
<li>杉田 祐樹, 米谷 竜, 佐藤 洋一, &ldquo;一人称視点映像における視線情報を活用した自己アクティビティ認識&rdquo;, 第18回 画像の認識理解シンポジウム, 2015</li>
<li>樋口 未来, 木谷 クリス 真実, 米谷 竜, 佐藤 洋一, &ldquo;一人称視点映像を用いた話者間の相対的地位の推定&rdquo;, 第18回 画像の認識理解シンポジウム, 2015</li>
<li>樋口啓太, 米谷竜, 佐藤洋一: &ldquo;遠隔作業支援シナリオにおける注視位置可視化の効果&rdquo;, 第23回インタラクティブシステムとソフトウェアに関するワークショップ, 2015</li>
<li>神窪利絵, 樋口啓太, 米谷竜, 小池英樹, 佐藤洋一: &ldquo;弱視者のための視線計測を用いたウェブアクセシビリティの向上&rdquo;, 電子情報通信学会福祉情報工学研究会, 信学技報WIT2015-75, 2015</li>
<li>Ryo Yonetani, Hiroaki Kawashima, and Takashi Matsuyama: Modeling Spatiotemporal Correlations between Video Saliency and Gaze Dynamics&rdquo;, 研究報告コンピュータビジョンとイメージメディア, 2014-CVIM-192(32), pp. 1-16, 2014</li>
<li>米谷竜, 川嶋宏彰, 松山隆司: &ldquo;映像閲覧行動の時空間ずれ構造モデルを用いた注視点予測&rdquo;, 信学技報, vol. 113, no. 196, PRMU2013-41, pp. 57-62, 2013**（2013年度PRMU研究奨励賞）**</li>
<li>Ryo Yonetani, Hiroaki Kawashima, Takashi Matsuyama: &ldquo;Learning Spatiotemporal Gaps between Where We Look and What We Focus on&rdquo;, 第16回 画像の認識理解シンポジウム, 2013</li>
<li>下西慶, 川嶋宏彰, 米谷竜, 松山隆司: &ldquo;視線運動解析による興味アスペクトの推定&rdquo;, 信学技報, vol. 113, no. 75, PRMU2013-28, pp. 53-58, 2013</li>
<li>石川惠理奈, 米谷竜, 川嶋宏彰, 平山高嗣, 松山隆司: &ldquo;提示コンテンツのデザイン構造を用いた視線運動の意味理解&rdquo;, 電子情報通信学会技術報告, PRMU2012-60, vol. 112, no. 225, pp.47-52, 2012</li>
<li>米谷竜, 川嶋宏彰, 加藤丈和, 松山隆司: &ldquo;映像の顕著性変動モデルを用いた視聴者の集中状態推定&rdquo;, 第15回 画像の認識・理解シンポジウム, 2012**（MIRU優秀学生論文賞）**</li>
<li>石川惠理奈, 米谷竜, 平山高嗣, 松山隆司: &ldquo;Gaze Mirroringによる注視模倣効果の分析&rdquo;, ヒューマンインタフェースシンポジウム2011, pp.561-566, 2011</li>
<li>米谷竜, 川嶋宏彰, 平山高嗣, 松山隆司: &ldquo;映像の顕著性変動と視線運動の時空間相関分析に基づいた集中状態推定&rdquo;, 情報処理学会研究会資料, CVIM178-16, 2011</li>
<li>米谷竜, 川嶋宏彰, 平山高嗣, 松山隆司: &ldquo;注視オブジェクト推定のための動的コンテンツデザインとその評価&rdquo;, 情報処理学会創立50周年記念（第72回）全国大会, 32N-1, pp. 5-141-142, 2010</li>
<li>米谷竜, 川嶋宏彰, 平山高嗣, 松山隆司: &ldquo;Gaze Probing, &ldquo;イベント提示に基づく注視対象推定&rdquo;, 第12回画像の認識・理解シンポジウム, pp.1713-1720, 2009</li>
<li>米谷竜, 川嶋宏彰, 平山高嗣, 松山隆司: &ldquo;提示イベントと眼球動作との同期構造分析に基づく注視対象推定&rdquo;, 情報処理学会研究会資料 CVIM 167-16, 2009</li>
</ul>
<h4 id="特許">特許</h4>
<p><a href="https://patents.google.com/?inventor=Ryo+Yonetani">https://patents.google.com/?inventor=Ryo+Yonetani</a></p>


  

  
  
  

</div>


    
      </div>
    

    </div>
  </section>



  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">
  

  <p class="powered-by">
    
  </p>

  
  






  <p class="powered-by">
    
    
    
    Published with
    <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a>  —
    the free, <a href="https://github.com/wowchemy/wowchemy-hugo-modules" target="_blank" rel="noopener">
    open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">引用</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> コピー
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> ダウンロード
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>

      
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      

      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js" integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/ja/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"結果が見つかりませんでした","placeholder":"検索...","results":"results found"};
      const content_type = {
        'post': "投稿",
        'project': "プロジェクト",
        'publication' : "発表文献",
        'talk' : "登壇",
        'slides' : "Slides"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    <script>
      if (window.netlifyIdentity) {
        window.netlifyIdentity.on("init", user => {
          if (!user) {
            window.netlifyIdentity.on("login", () => {
              document.location.href = "/admin/";
            });
          }
        });
      }
    </script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/wowchemy.min.76130252bc8c287b25144aa7a54dcd1f.js"></script>

    






</body>
</html>
