---
layout: post
date: 2018-04-17 00:00
thumbnail:
title: Datasets for First-Person Vision
---

In order to promote future research on first-person vision, we have released a part of datasets used in our work.

<!--more-->


## UTokyo Paired Ego-Video (PEV) Dataset (CVPR'16)

<img class="img-responsive" src="/images/yks-cvpr2016.png">

UTokyo PEV Dataset contains 1,226 pairs of first-person clips extracted from the ones recorded synchronously during dyadic conversations.
Each pair captures one of pointing, attention, passing/receiving items, positive/negative reactions, hand gestures, or idle actions from the first-person and second-person points-of-view.
#### [>> LINK (201.5 MB, LAST UPDATE: 2018/04/17)](https://www.dropbox.com/s/ihy5qdoliktfozx/yks_cvpr2016_release.zip?dl=0)

---

## UTokyo Navigation Dataset (ECCV'16)

<img class="img-responsive" src="/images/yks-eccv2016.png">

UTokyo Navigation Dataset contains multiple first-person videos recorded by people walking around a university campus to visit landmarks (e.g., map signs, vending machines.) Since we cannnot disclose original videos due to privacy concerns, we instead publish some features (per-frame deep features extracted using places CNN, optical-flow-based motion features, etc) extracted from the videos.

#### [>> LINK (10.82 GB, LAST UPDATE: 2018/04/17)](https://www.dropbox.com/s/jt8d0ru2l2atvm0/yks_eccv2016_release.zip?dl=0)


---

## UTokyo Ego-Surf Dataset (CVPR'15, TPAMI'18)

<img class="img-responsive" src="/images/egosurf.png">

UTokyo Ego-Surf Dataset contains 8 diverse groups of first-person videos recorded synchronously during face-to-face conversations. Each video was recorded for 30 sec at 60 fps.
#### [>> LINK (42.7 MB)](https://www.dropbox.com/s/onx530l5doqbrsb/yks_cvpr2015.zip?dl=0)
